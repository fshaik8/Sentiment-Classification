{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e94b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer, TextClassificationPipeline\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = pd.read_csv('data/obama_cleaned.csv')\n",
    "dfo = dfo.rename(columns={'tweets' : 'text', 'class' : 'label'})\n",
    "\n",
    "dfr = pd.read_csv('data/romney_cleaned.csv')\n",
    "dfr = dfr.rename(columns={'tweets' : 'text', 'class' : 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77694489",
   "metadata": {},
   "source": [
    "# Pre-trained model: BERTweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed82996",
   "metadata": {},
   "source": [
    "Fine-tuning using our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19350299",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xo = dfo['text']\n",
    "yo = dfo['label'].map({1 : 2, 0 : 1, -1 : 0})\n",
    "Xo_train, Xo_eval, yo_train, yo_eval = train_test_split(Xo, yo, test_size = 0.25, random_state = 21)\n",
    "\n",
    "Xr = dfr['text']\n",
    "yr = dfr['label'].map({1 : 2, 0 : 1, -1 : 0})\n",
    "Xr_train, Xr_eval, yr_train, yr_eval = train_test_split(Xr, yr, test_size = 0.25, random_state = 21)\n",
    "\n",
    "\n",
    "traindf_o = pd.concat([Xo_train,yo_train], axis = 1)\n",
    "evaldf_o = pd.concat([Xo_eval,yo_eval], axis = 1)\n",
    "\n",
    "traindf_r = pd.concat([Xr_train,yr_train], axis = 1)\n",
    "evaldf_r = pd.concat([Xr_eval,yr_eval], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254787af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o = Dataset.from_pandas(traindf_o, split = 'train')\n",
    "eval_o = Dataset.from_pandas(evaldf_o, split = 'eval')\n",
    "\n",
    "train_r = Dataset.from_pandas(traindf_r, split = 'train')\n",
    "eval_r = Dataset.from_pandas(evaldf_r, split = 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56bb2b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "tokenized_train_o = train_o.map(tokenize_function, batched=True)\n",
    "tokenized_eval_o = eval_o.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train_r = train_r.map(tokenize_function, batched=True)\n",
    "tokenized_eval_r = eval_o.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_o = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\", num_labels=3)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_o = TrainingArguments(output_dir=\"checkpoints/test_trainer_o\", evaluation_strategy=\"epoch\", num_train_epochs=2)\n",
    "\n",
    "trainer_o = Trainer(\n",
    "    model=model_o,\n",
    "    args=training_args_o,\n",
    "    train_dataset=tokenized_train_o,\n",
    "    eval_dataset=tokenized_eval_o,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_o.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_o.save_model('models/obama_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\", num_labels=3)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_r = TrainingArguments(output_dir=\"checkpoints/test_trainer_r\", evaluation_strategy=\"epoch\", num_train_epochs=3)\n",
    "\n",
    "trainer_r = Trainer(\n",
    "    model=model_r,\n",
    "    args=training_args_r,\n",
    "    train_dataset=tokenized_train_r,\n",
    "    eval_dataset=tokenized_eval_r,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_r.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cbb9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_r.save_model('models/romney_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b588c",
   "metadata": {},
   "source": [
    "# Load from checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8394d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_o = AutoModelForSequenceClassification.from_pretrained(\"checkpoints/test_trainer_o\", num_labels=3)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_o = TrainingArguments(output_dir=\"test_trainer_o\", evaluation_strategy=\"epoch\", num_train_epochs=2)\n",
    "\n",
    "trainer_o = Trainer(\n",
    "    model=model_o,\n",
    "    args=training_args_o,\n",
    "    train_dataset=tokenized_train_o,\n",
    "    eval_dataset=tokenized_test_o,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_o.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9940c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = AutoModelForSequenceClassification.from_pretrained(\"checkpoints/test_trainer_r\", num_labels=3)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_r = TrainingArguments(output_dir=\"checkpoints/test_trainer_r\", evaluation_strategy=\"epoch\", num_train_epochs=3)\n",
    "\n",
    "trainer_r = Trainer(\n",
    "    model=model_r,\n",
    "    args=training_args_r,\n",
    "    train_dataset=tokenized_train_r,\n",
    "    eval_dataset=tokenized_eval_r,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_r.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9522d5",
   "metadata": {},
   "source": [
    "# Load finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_o = AutoModelForSequenceClassification.from_pretrained('models/obama_final')\n",
    "model_r = AutoModelForSequenceClassification.from_pretrained('models/romney_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_o = TextClassificationPipeline(model=model_o, tokenizer=tokenizer)\n",
    "pipe_r = TextClassificationPipeline(model=model_r, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab5b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_o = pd.read_csv('data/test_obama_cleaned.csv')\n",
    "test_r = pd.read_csv('data/test_romney_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_o = list()\n",
    "for tweet in test_o['tweets']:\n",
    "    pred_o.append(pipe_o(tweet)[0]['label'])\n",
    "\n",
    "pred_r = list()\n",
    "for tweet in test_r['tweets']:\n",
    "    pred_r.append(pipe_r(tweet)[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8cfc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_o = test_o['class'].map({-1: 'NEG', 0: 'NEU', 1:'POS'})\n",
    "target_r = test_r['class'].map({-1: 'NEG', 0: 'NEU', 1:'POS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_o = accuracy_score(target_o, pred_o)\n",
    "prec_o = precision_score(target_o, pred_o, average = None, zero_division = np.nan)\n",
    "rec_o = recall_score(target_o, pred_o, average = None)\n",
    "f1_o = f1_score(target_o, pred_o, average = None)\n",
    "print(\"Accuracy:\", acc_o)\n",
    "print(\"Precision:\", prec_o)\n",
    "print(\"Recall:\", rec_o)\n",
    "print(\"F1:\", f1_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c174fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_r = accuracy_score(target_r, pred_r)\n",
    "prec_r = precision_score(target_r, pred_r, average = None, zero_division = np.nan)\n",
    "rec_r = recall_score(target_r, pred_r, average = None)\n",
    "f1_r = f1_score(target_r, pred_r, average = None)\n",
    "print(\"Accuracy:\", acc_r)\n",
    "print(\"Precision:\", prec_r)\n",
    "print(\"Recall:\", rec_r)\n",
    "print(\"F1:\", f1_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
